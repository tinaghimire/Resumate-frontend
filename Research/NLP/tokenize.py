# from nltk.tokenize import regexp_tokenize
# from nltk.tokenize import TweetTokenizer

from nltk.tokenize import word_tokenize

# Split the string into tokens: tokens
print(word_tokenize("Hi there"))
